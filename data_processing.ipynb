{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "lags = 12\n",
    "train = \"/Users/marleywetini/repos/intelligentSystems/data/Scats Data October 2006.csv\"\n",
    "test = \"/Users/marleywetini/repos/intelligentSystems/data/SCAT Test Data.xlsx\"\n",
    "\n",
    "# Step 1: Load and clean the data\n",
    "df = pd.read_excel(test, header=1).fillna(0)\n",
    "\n",
    "# Step 2: Define the flow columns (V00 to V95 for 96 time intervals)\n",
    "flow_columns = [f\"V{str(i).zfill(2)}\" for i in range(96)]\n",
    "grouped_data = df.groupby(['NB_LATITUDE', 'NB_LONGITUDE'])[flow_columns].apply(lambda x: x.values.tolist())\n",
    "flow_data = grouped_data.values\n",
    "df_flow_data = np.array(flow_data)\n",
    "data_scaler = MinMaxScaler()\n",
    "latlong_scaler = MinMaxScaler()\n",
    "latlong_data = df[['NB_LATITUDE', 'NB_LONGITUDE']]\n",
    "latlong_scaled = latlong_scaler.fit_transform(latlong_data)\n",
    "train_data = []\n",
    "\n",
    "for i, flow in enumerate(df_flow_data):\n",
    "    flow = np.array(flow).flatten()\n",
    "    flow = data_scaler.fit_transform(flow.reshape(-1,1)).reshape(1, -1)\n",
    "    for j in range(0, len(flow[0]) - lags + 1):  # Iterating over each possible lag of 12\n",
    "        lagged_flow = flow[0][j:j+lags + 1]  # Get the flow data for a lag of 12\n",
    "        # Attach corresponding latlong data\n",
    "        latlong = latlong_scaled[i]  # Get the lat/long for the current location\n",
    "        # Combine latlong and flow data\n",
    "        combined_arr = np.hstack((latlong, lagged_flow))\n",
    "        # Append the combined array to the training data\n",
    "        train_data.append(combined_arr)\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "print(train_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=.75)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Process Data\n",
    "Reshape and split data into train and test data.\n",
    "\n",
    "Parameters:\n",
    "    df (df.DataFram): dataframe of the data\n",
    "    lags (int): time lag\n",
    "\n",
    "Returns:\n",
    "    X_train (np.ndarray)\n",
    "    y_train (np.ndarray)\n",
    "    X_test (np.ndarray)\n",
    "    y_test (np.ndarray)\n",
    "    flow_scaler (func)\n",
    "\"\"\"\n",
    "def scaler(min, max):\n",
    "\tdef _scaler(x):\n",
    "\t\treturn (x - min) / (max - min)\n",
    "\treturn _scaler\n",
    "\n",
    "def rescaler(min, max):\n",
    "\tdef _rescaler(x):\n",
    "\t\treturn x * (max - min) + min\n",
    "\treturn _rescaler\n",
    "flow_group = np.char.mod(\"V%02d\", np.arange(0, 96))\n",
    "grouped = df.groupby(['NB_LATITUDE', 'NB_LONGITUDE'])[flow_group].apply(lambda x: x.values.tolist())\n",
    "flow_data = grouped.values\n",
    "flow_max = np.array(flow_data.max()).max()\n",
    "flow_min = np.array(flow_data.min()).min()\n",
    "flow_scaler = scaler(flow_min, flow_max)\n",
    "flow_rescaler = rescaler(flow_min, flow_max)\n",
    "latlong_data = np.array(grouped.index.to_list())\n",
    "latlong_scaler = MinMaxScaler(feature_range=(0, 1)).fit(latlong_data.reshape(-1, 1))\n",
    "latlong_data = latlong_scaler.transform(latlong_data.reshape(-1, 1)).reshape(-1, 2)\n",
    "\n",
    "train = []\n",
    "i = 0\n",
    "# Iterate over the flow data\n",
    "for flow in grouped.values:\n",
    "    while i != 1:  # Assuming you only want to process 3 groups, adjust this logic as needed\n",
    "        flow = np.array(flow, dtype=float).flatten()  # Flatten the flow data\n",
    "        \n",
    "        # Scale the flow data\n",
    "        flow = np.vectorize(flow_scaler)(flow)\n",
    "        print(f'FLOW {i}')  # Debug print\n",
    "        \n",
    "        # Define the indices and offsets for lag-based processing\n",
    "        indices = np.arange(lags, len(flow))\n",
    "        offset = np.arange(-lags, 1)\n",
    "        print(offset)  # Print scaled flow for debugging\n",
    "        \n",
    "        # Reshape flow data according to lag offsets\n",
    "        flow = flow[indices[:, np.newaxis] + offset]\n",
    "        # Prepare latlong data, matching the shape of flow\n",
    "        latlong = np.tile(latlong_data[i], (len(flow), 1))\n",
    "        \n",
    "        # Combine latlong and flow data\n",
    "        combined_arr = np.hstack((latlong, flow))\n",
    "        print(combined_arr)\n",
    "        # Add the combined data to the training array\n",
    "        train.extend(combined_arr)\n",
    "        \n",
    "        # Increment the counter\n",
    "        i += 1\n",
    "train = np.array(train)\n",
    "X = train[:, :-1]\n",
    "y = train[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
